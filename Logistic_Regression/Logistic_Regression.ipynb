{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obseity Classification problem\n",
    "# import necessary classification problem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "# cheking for Nulls\n",
    "df.isna().sum()\n",
    "\n",
    "df.duplicated().sum() #  there are some dulplicates\n",
    "\n",
    "df = df.drop_duplicates() # removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and making dummy for the categorical variables\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns that needs to be converted either with LE or OHE\n",
    "le_columns = ['CAEC','SCC','CALC','NObeyesdad']\n",
    "ohe_columns = ['Gender','family_history_with_overweight','FAVC','SMOKE','MTRANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for One Hot Encoding and Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "def label_ecoder(data,my_list):\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    for item in my_list:\n",
    "        data[item] = encoder.fit_transform(data[item])\n",
    "\n",
    "        print(f\"column : {item}\")\n",
    "        print(f\"Unique values before Encoding :{df[item].astype('category').cat.categories.tolist()}\")\n",
    "        print(f\"Unique values after Encoding : {df[item].nunique()}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def ohe_encoder(data, my_list):\n",
    "    ohe = OneHotEncoder(sparse_output=False,drop = 'first')\n",
    "    data = data.copy()\n",
    "    for item in my_list:\n",
    "        if item in data.columns:\n",
    "            transformed = ohe.fit_transform(data[[item]])\n",
    "            ohe_col = ohe.get_feature_names_out([item])\n",
    "\n",
    "            df_ohe = pd.DataFrame(transformed, columns = ohe_col, index=data.index)\n",
    "\n",
    "            data = pd.concat([data, df_ohe],axis = 1)\n",
    "\n",
    "            data.drop(columns = [item], inplace = True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = label_ecoder(df,le_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = ohe_encoder(df1,ohe_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start with the Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay \n",
    "\n",
    "X = final_df.drop(columns = 'NObeyesdad', axis = 1)\n",
    "y = final_df['NObeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Standardization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a logistic Regression\n",
    "\n",
    "log_regression = LogisticRegression(max_iter= 250)\n",
    "\n",
    "log_regression.fit(scaled_X_train,y_train)\n",
    "log_pred = log_regression.predict(scaled_X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_estimator(log_regression, scaled_X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
